# Import necessary libraries
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, avg

# Initialize Spark session
spark = SparkSession.builder.appName("ETL Pipeline").getOrCreate()

storage_account_name = "tfstaf76bdd752eb03019"
key_vault_scope = "keyvault-managed"
storage_account_key = dbutils.secrets.get(scope=key_vault_scope, key="storage-access-key")
container_name = "databricks-container"

# Set up the Spark configuration
spark.conf.set(f"fs.azure.account.key.{storage_account_name}.dfs.core.windows.net", storage_account_key)

# Read the CSV file from ADLS
adls_path = f"abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/raw/sample_data.csv"
df = spark.read.csv(adls_path, header=True, inferSchema=True)

# Display the raw data
print("Raw Data:")
df.show()

# Perform transformations
# Example 1: Filter rows where age is greater than 30
cleansed_df = df.filter(col("age") > 30)

# Example 2: Aggregate data by city and calculate average salary
aggregated_df = df.groupBy("city").agg(avg("salary").alias("avg_salary"))

# Display transformed data
print("Cleansed Data:")
cleansed_df.show()

print("Aggregated Data:")
aggregated_df.show()

# Save cleansed data back to ADLS
cleansed_output_path = f"abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/cleansed/cleansed_data.csv"
cleansed_df.write.mode("overwrite").csv(cleansed_output_path, header=True)

# Read SQL Server password from Azure Key Vault
key_vault_scope = "keyvault-managed"
sql_password = dbutils.secrets.get(scope=key_vault_scope, key="sql-server-admin-password")

# Save aggregated data to SQL Server
sql_server_url = "jdbc:sqlserver://sql-server-f62d4d94a102d5eb.database.windows.net:1433;database=sql-db-f62d4d94a102d5eb"
sql_server_properties = {
    "user": "tatestsql2025",
    "password": sql_password,  # Use the password from Key Vault
    "driver": "com.microsoft.sqlserver.jdbc.SQLServerDriver"
}
aggregated_df.write.jdbc(url=sql_server_url, table="aggregated_data", mode="overwrite", properties=sql_server_properties)
